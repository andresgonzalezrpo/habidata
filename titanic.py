#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ejemplo pr치ctico de aprendizaje supervisado: Predicci칩n de supervivencia en el Titanic
Este script implementa un flujo de trabajo completo de machine learning para predecir
qu칠 pasajeros sobrevivieron al naufragio del Titanic.

Autor: Tania Rodriguez - Eder Lara
Fecha: 6 de junio de 2025
"""

# Importar bibliotecas necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

'''
Bibliotecas Fundamentales
Estas son las librer칤as b치sicas para casi cualquier proyecto de ciencia de datos en Python.

import numpy as np

쯈u칠 hace? Es la librer칤a fundamental para la computaci칩n num칠rica. Su principal objeto es el array multidimensional (ndarray), que es mucho m치s r치pido y eficiente que las listas de Python para operaciones matem치ticas.
쯇ara qu칠 se usa? Para todo tipo de c치lculos matem치ticos, 치lgebra lineal, transformaciones y manipulaci칩n de n칰meros a gran escala. Es la base sobre la que se construye Pandas.

import pandas as pd

쯈u칠 hace? Proporciona estructuras de datos de alto rendimiento y f치ciles de usar, principalmente el DataFrame, que es como una tabla de Excel o una tabla de SQL dentro de Python.
쯇ara qu칠 se usa? Para leer, escribir, limpiar, filtrar, transformar, agrupar y analizar datos estructurados. Es la herramienta principal para la manipulaci칩n de datos. 游냪

import matplotlib.pyplot as plt

쯈u칠 hace? Es la librer칤a de visualizaci칩n m치s veterana y fundamental de Python. Te da un control total para crear una amplia variedad de gr치ficos est치ticos, animados e interactivos.
쯇ara qu칠 se usa? Para crear gr치ficos b치sicos y personalizados como l칤neas, barras, histogramas y diagramas de dispersi칩n.

import seaborn as sns

쯈u칠 hace? Es una librer칤a de visualizaci칩n basada en Matplotlib. Ofrece una interfaz de m치s alto nivel para crear gr치ficos estad칤sticos m치s atractivos y complejos con menos c칩digo.
쯇ara qu칠 se usa? Para crear visualizaciones estad칤sticas avanzadas como mapas de calor, diagramas de viol칤n o gr치ficos de pares, que ayudan a explorar y entender las relaciones en los datos. 游꿛
'''

# Para preprocesamiento
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

'''
Para Preprocesamiento
Estos m칩dulos de scikit-learn se usan para preparar tus datos antes de entrenar un modelo.

from sklearn.model_selection import ...

    train_test_split: Divide tu conjunto de datos en dos partes: una para entrenar el modelo y otra para probar qu칠 tan bien funciona con datos que nunca ha visto. Es un paso esencial para evitar el sobreajuste (overfitting).
    cross_val_score: Eval칰a el modelo de forma m치s robusta mediante la validaci칩n cruzada. Divide los datos en m칰ltiples "pliegues" (folds) y entrena/prueba el modelo varias veces, d치ndote un promedio de su rendimiento.
    GridSearchCV: Ayuda a encontrar los mejores hiperpar치metros para un modelo. Prueba sistem치ticamente una "rejilla" (grid) de combinaciones de par치metros y te dice cu치l funcion칩 mejor.

from sklearn.preprocessing import ...

    StandardScaler: Estandariza las caracter칤sticas num칠ricas para que tengan una media de 0 y una desviaci칩n est치ndar de 1. Es crucial para algoritmos sensibles a la escala de los datos, como las M치quinas de Soporte Vectorial (SVM).
    OneHotEncoder: Convierte variables categ칩ricas (ej: "Rojo", "Verde", "Azul") en un formato num칠rico que el modelo pueda entender, creando nuevas columnas binarias (0s y 1s) para cada categor칤a.

from sklearn.impute import SimpleImputer

    쯈u칠 hace? Maneja los valores faltantes (nulos o NaN) en tu dataset.
    쯇ara qu칠 se usa? Para rellenar los datos faltantes con un valor espec칤fico, como la media, la mediana o la moda (el valor m치s frecuente) de la columna.

from sklearn.compose import ColumnTransformer

    쯈u칠 hace? Permite aplicar diferentes transformaciones a diferentes columnas de tu dataset.
    쯇ara qu칠 se usa? Es muy 칰til para, por ejemplo, aplicar StandardScaler a las columnas num칠ricas y OneHotEncoder a las columnas categ칩ricas, todo en un solo paso.

from sklearn.pipeline import Pipeline

    쯈u칠 hace? Encadena m칰ltiples pasos de preprocesamiento y un modelo final en un solo objeto.
    쯇ara qu칠 se usa? Para organizar el flujo de trabajo, evitar la fuga de datos (data leakage) y facilitar la aplicaci칩n de las mismas transformaciones a los datos de entrenamiento y prueba. Es como crear una l칤nea de ensamblaje para tu modelo.
'''

# Para modelado
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import joblib

'''
Para Modelado
Estas son las clases que representan los algoritmos de Machine Learning que vas a entrenar.

from sklearn.linear_model import LogisticRegression

    Regresi칩n Log칤stica: A pesar de su nombre, es un modelo de clasificaci칩n. Es un algoritmo lineal simple pero potente, ideal como punto de partida para problemas de clasificaci칩n binaria (S칤/No).

from sklearn.tree import DecisionTreeClassifier

    츼rbol de Decisi칩n: Un modelo que aprende una serie de "preguntas" (reglas de decisi칩n) para clasificar los datos. Es muy f치cil de interpretar y visualizar.

from sklearn.ensemble import RandomForestClassifier

    Random Forest (Bosque Aleatorio): Un modelo de ensamble que construye muchos 치rboles de decisi칩n y combina sus predicciones. Generalmente, es mucho m치s preciso y robusto que un solo 치rbol de decisi칩n. 游꺕

from sklearn.svm import SVC

    Support Vector Classifier (M치quina de Soporte Vectorial): Un modelo de clasificaci칩n muy potente que funciona encontrando el "hiperplano" que mejor separa las clases en los datos.
'''

# Para evaluaci칩n
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

'''
Para Evaluaci칩n
Estas funciones te ayudan a medir el rendimiento de tu modelo y a entender qu칠 tan buenas son sus predicciones.

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

    accuracy_score (Exactitud): El porcentaje de predicciones correctas. (Correctas / Total).
    precision_score (Precisi칩n): De todas las veces que el modelo predijo "Positivo", 쯖u치ntas acert칩? Es importante cuando los falsos positivos son costosos.
    recall_score (Sensibilidad): De todos los casos que eran realmente "Positivos", 쯖u치ntos logr칩 identificar el modelo? Es clave cuando los falsos negativos son peligrosos (ej: diagn칩stico m칠dico).
    f1_score: La media arm칩nica de precisi칩n y sensibilidad. Ofrece un buen balance entre ambas, especialmente 칰til cuando las clases est치n desbalanceadas.

from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

    confusion_matrix (Matriz de Confusi칩n): Una tabla que desglosa las predicciones en Verdaderos Positivos, Falsos Positivos, Verdaderos Negativos y Falsos Negativos. Es la base para calcular las dem치s m칠tricas.
    classification_report (Reporte de Clasificaci칩n): Un resumen en texto que muestra la precisi칩n, sensibilidad y F1-score para cada clase.
    roc_curve y roc_auc_score (Curva ROC y AUC): Herramientas para evaluar el rendimiento de un clasificador binario. La curva ROC visualiza el equilibrio entre la tasa de verdaderos positivos y falsos positivos, y el AUC (츼rea Bajo la Curva) resume este rendimiento en un solo n칰mero (1.0 es perfecto, 0.5 es aleatorio).

'''

# Configuraci칩n para visualizaciones
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

# Ignorar advertencias
import warnings
warnings.filterwarnings('ignore')

print("Entorno configurado correctamente.")

# Funci칩n para descargar los datos del Titanic
def cargar_datos():
    """
    Carga los datos del Titanic desde GitHub si no est치n disponibles localmente.
    
    Returns:
        pandas.DataFrame: Datos del Titanic
    """
    try:
        data = pd.read_csv('titanic.csv')
        print("Datos cargados correctamente desde archivo local.")
    except FileNotFoundError:
        print("Archivo no encontrado. Descargando datos...")
        url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
        data = pd.read_csv(url)
        # Guardar localmente para uso futuro
        data.to_csv('titanic.csv', index=False)
        print("Datos descargados correctamente y guardados como 'titanic.csv'.")
    
    return data

# Funci칩n para explorar los datos
def explorar_datos(data):
    """
    Realiza un an치lisis exploratorio b치sico de los datos.
    
    Args:
        data (pandas.DataFrame): Datos del Titanic
    """
    print("\nPrimeras 5 filas del conjunto de datos:")
    print(data.head())
    
    print("\nInformaci칩n del conjunto de datos:")
    print(data.info())
    
    print("\nEstad칤sticas descriptivas:")
    print(data.describe())
    
    print("\nValores faltantes por columna:")
    print(data.isnull().sum())
    
    # Guardar visualizaciones en archivos
    # Distribuci칩n de la variable objetivo
    plt.figure(figsize=(8, 6))
    sns.countplot(x='Survived', data=data)
    plt.title('Distribuci칩n de Supervivencia')
    plt.xlabel('Sobrevivi칩 (1) / No Sobrevivi칩 (0)')
    plt.ylabel('Cantidad de Pasajeros')
    plt.savefig('titanic_supervivencia.png', dpi=300, bbox_inches='tight')
    
    # Tasa de supervivencia por sexo
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Sex', y='Survived', data=data, ci=None)
    plt.title('Tasa de Supervivencia por Sexo')
    plt.xlabel('Sexo')
    plt.ylabel('Tasa de Supervivencia')
    plt.savefig('titanic_supervivencia_sexo.png', dpi=300, bbox_inches='tight')
    
    # Tasa de supervivencia por clase
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Pclass', y='Survived', data=data, ci=None)
    plt.title('Tasa de Supervivencia por Clase')
    plt.xlabel('Clase')
    plt.ylabel('Tasa de Supervivencia')
    plt.savefig('titanic_supervivencia_clase.png', dpi=300, bbox_inches='tight')
    
    # Distribuci칩n de edades
    plt.figure(figsize=(12, 6))
    sns.histplot(data=data, x='Age', hue='Survived', multiple='stack', bins=30)
    plt.title('Distribuci칩n de Edades por Supervivencia')
    plt.xlabel('Edad')
    plt.ylabel('Cantidad de Pasajeros')
    plt.legend(title='Sobrevivi칩', labels=['No', 'S칤'])
    plt.savefig('titanic_edad_supervivencia.png', dpi=300, bbox_inches='tight')
    
    print("\nVisualizaciones guardadas como archivos PNG.")
    
    # Crear una caracter칤stica de tama침o de familia
    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1  # +1 para incluir al pasajero
    
    # Tasa de supervivencia por tama침o de familia
    plt.figure(figsize=(10, 6))
    sns.barplot(x='FamilySize', y='Survived', data=data, ci=None)
    plt.title('Tasa de Supervivencia por Tama침o de Familia')
    plt.xlabel('Tama침o de Familia')
    plt.ylabel('Tasa de Supervivencia')
    plt.savefig('titanic_familia_supervivencia.png', dpi=300, bbox_inches='tight')
    
    return data

# Funci칩n para preparar los datos
def preparar_datos(data):
    """
    Prepara los datos para el modelado, incluyendo selecci칩n de caracter칤sticas,
    divisi칩n en conjuntos de entrenamiento y prueba, y creaci칩n de pipelines de preprocesamiento.
    
    Args:
        data (pandas.DataFrame): Datos del Titanic
        
    Returns:
        tuple: X_train, X_test, y_train, y_test, preprocessor
    """
    # Seleccionar caracter칤sticas relevantes
    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
    X = data[features]
    y = data['Survived']
    
    # Dividir en conjuntos de entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    print(f"Tama침o del conjunto de entrenamiento: {X_train.shape[0]} muestras")
    print(f"Tama침o del conjunto de prueba: {X_test.shape[0]} muestras")
    
    # Identificar tipos de columnas
    numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']
    categorical_features = ['Pclass', 'Sex', 'Embarked']
    
    # Crear transformadores para diferentes tipos de columnas
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    # Combinar transformadores usando ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])
    
    # Verificar la forma de los datos despu칠s del preprocesamiento
    X_train_preprocessed = preprocessor.fit_transform(X_train)
    print(f"Forma de X_train despu칠s del preprocesamiento: {X_train_preprocessed.shape}")
    
    return X_train, X_test, y_train, y_test, preprocessor

# Funci칩n para entrenar y evaluar modelos
def entrenar_evaluar_modelos(X_train, X_test, y_train, y_test, preprocessor):
    """
    Entrena varios modelos y eval칰a su rendimiento.
    
    Args:
        X_train, X_test, y_train, y_test: Conjuntos de datos de entrenamiento y prueba
        preprocessor: Transformador de columnas para preprocesamiento
        
    Returns:
        tuple: Mejor modelo, nombre del mejor modelo, resultados de todos los modelos
    """
    # Definir modelos a evaluar
    models = {
        'Regresi칩n Log칤stica': LogisticRegression(max_iter=1000, random_state=42),
        '츼rbol de Decisi칩n': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(random_state=42),
        'SVM': SVC(probability=True, random_state=42)
    }
    
    # Crear pipelines para cada modelo
    pipelines = {}
    for name, model in models.items():
        pipelines[name] = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('model', model)
        ])
    
    # Evaluar modelos con validaci칩n cruzada
    results = {}
    for name, pipeline in pipelines.items():
        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')
        results[name] = {
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std()
        }
        print(f"{name}: Exactitud CV = {cv_scores.mean():.4f} (췀{cv_scores.std():.4f})")
    
    # Visualizar resultados de validaci칩n cruzada
    cv_means = [results[name]['cv_mean'] for name in models.keys()]
    cv_stds = [results[name]['cv_std'] for name in models.keys()]
    
    plt.figure(figsize=(12, 6))
    plt.bar(models.keys(), cv_means, yerr=cv_stds, capsize=10)
    plt.title('Comparaci칩n de Modelos (Validaci칩n Cruzada)')
    plt.xlabel('Modelo')
    plt.ylabel('Exactitud Media')
    plt.ylim([0.7, 0.9])  # Ajustar seg칰n los resultados
    plt.grid(axis='y')
    plt.savefig('titanic_comparacion_modelos.png', dpi=300, bbox_inches='tight')
    
    # Seleccionar el mejor modelo basado en validaci칩n cruzada
    best_model_name = max(results, key=lambda x: results[x]['cv_mean'])
    best_pipeline = pipelines[best_model_name]
    print(f"\nMejor modelo: {best_model_name} con exactitud CV de {results[best_model_name]['cv_mean']:.4f}")
    
    # Entrenar el mejor modelo en todo el conjunto de entrenamiento
    best_pipeline.fit(X_train, y_train)
    
    # Evaluar en el conjunto de prueba
    y_pred = best_pipeline.predict(X_test)
    y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]
    
    # M칠tricas de rendimiento
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    print("\nRendimiento en el conjunto de prueba:")
    print(f"Exactitud: {accuracy:.4f}")
    print(f"Precisi칩n: {precision:.4f}")
    print(f"Exhaustividad: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    
    # Matriz de confusi칩n
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matriz de Confusi칩n')
    plt.xlabel('Predicci칩n')
    plt.ylabel('Valor Real')
    plt.savefig('titanic_matriz_confusion.png', dpi=300, bbox_inches='tight')
    
    # Curva ROC
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    plt.figure(figsize=(10, 8))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Tasa de Falsos Positivos')
    plt.ylabel('Tasa de Verdaderos Positivos')
    plt.title('Curva ROC')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.savefig('titanic_curva_roc.png', dpi=300, bbox_inches='tight')
    
    # Informe de clasificaci칩n detallado
    print("\nInforme de Clasificaci칩n:")
    print(classification_report(y_test, y_pred))
    
    return best_pipeline, best_model_name, results

# Funci칩n para optimizar hiperpar치metros
def optimizar_hiperparametros(best_pipeline, best_model_name, X_train, y_train, X_test, y_test):
    """
    Optimiza los hiperpar치metros del mejor modelo.
    
    Args:
        best_pipeline: Pipeline del mejor modelo
        best_model_name: Nombre del mejor modelo
        X_train, y_train: Datos de entrenamiento
        X_test, y_test: Datos de prueba
        
    Returns:
        object: Modelo optimizado
    """
    # Definir espacio de b칰squeda de hiperpar치metros seg칰n el mejor modelo
    if best_model_name == 'Regresi칩n Log칤stica':
        param_grid = {
            'model__C': [0.01, 0.1, 1, 10, 100],
            'model__solver': ['liblinear', 'lbfgs'],
            'model__penalty': ['l1', 'l2']
        }
    elif best_model_name == '츼rbol de Decisi칩n':
        param_grid = {
            'model__max_depth': [None, 5, 10, 15, 20],
            'model__min_samples_split': [2, 5, 10],
            'model__min_samples_leaf': [1, 2, 4]
        }
    elif best_model_name == 'Random Forest':
        param_grid = {
            'model__n_estimators': [50, 100, 200],
            'model__max_depth': [None, 10, 20],
            'model__min_samples_split': [2, 5, 10],
            'model__min_samples_leaf': [1, 2, 4]
        }
    elif best_model_name == 'SVM':
        param_grid = {
            'model__C': [0.1, 1, 10, 100],
            'model__gamma': ['scale', 'auto', 0.1, 0.01],
            'model__kernel': ['rbf', 'linear']
        }
    
    # Realizar b칰squeda en cuadr칤cula
    print("\nIniciando optimizaci칩n de hiperpar치metros. Esto puede tomar un tiempo...")
    grid_search = GridSearchCV(
        best_pipeline,
        param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    
    # Mejores hiperpar치metros
    print("\nMejores hiperpar치metros:")
    print(grid_search.best_params_)
    print(f"Mejor puntuaci칩n de validaci칩n cruzada: {grid_search.best_score_:.4f}")
    
    # Evaluar modelo optimizado en el conjunto de prueba
    best_model = grid_search.best_estimator_
    y_pred_optimized = best_model.predict(X_test)
    y_pred_proba_optimized = best_model.predict_proba(X_test)[:, 1]
    
    # M칠tricas de rendimiento del modelo optimizado
    accuracy_opt = accuracy_score(y_test, y_pred_optimized)
    precision_opt = precision_score(y_test, y_pred_optimized)
    recall_opt = recall_score(y_test, y_pred_optimized)
    f1_opt = f1_score(y_test, y_pred_optimized)
    roc_auc_opt = roc_auc_score(y_test, y_pred_proba_optimized)
    
    print("\nRendimiento del modelo optimizado en el conjunto de prueba:")
    print(f"Exactitud: {accuracy_opt:.4f}")
    print(f"Precisi칩n: {precision_opt:.4f}")
    print(f"Exhaustividad: {recall_opt:.4f}")
    print(f"F1-Score: {f1_opt:.4f}")
    print(f"AUC-ROC: {roc_auc_opt:.4f}")
    
    return best_model

# Funci칩n para guardar el modelo
def guardar_modelo(model, filename):
    """
    Guarda un modelo entrenado en un archivo usando joblib.
    
    Args:
        model (object): El modelo entrenado que se va a guardar.
        filename (str): El nombre del archivo (ej. 'modelo.joblib').
    """
    try:
        joblib.dump(model, filename)
        print(f"\nModelo guardado exitosamente en el archivo: '{filename}'")
    except Exception as e:
        print(f"\nError al guardar el modelo: {e}")

# Funci칩n para interpretar el modelo
def interpretar_modelo(model, best_model_name, X_test, y_test, preprocessor):
    """
    Interpreta el modelo final para entender qu칠 caracter칤sticas son m치s importantes.
    
    Args:
        model: Modelo optimizado
        best_model_name: Nombre del mejor modelo
        X_test, y_test: Datos de prueba
        preprocessor: Transformador de columnas para preprocesamiento
    """
    # Extraer importancia de caracter칤sticas (si el modelo lo permite)
    if best_model_name in ['츼rbol de Decisi칩n', 'Random Forest']:
        # Para 치rboles, podemos obtener la importancia directamente
        numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']
        categorical_features = ['Pclass', 'Sex', 'Embarked']
        
        # Obtener nombres de caracter칤sticas despu칠s de one-hot encoding
        ohe = model.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot']
        cat_feature_names = ohe.get_feature_names_out(categorical_features)
        
        # Combinar nombres de caracter칤sticas
        feature_names = np.array(numeric_features + list(cat_feature_names))
        
        # Obtener importancias
        importances = model.named_steps['model'].feature_importances_
        
        # Crear DataFrame para visualizaci칩n
        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importances
        })
        
        # Ordenar por importancia
        feature_importance = feature_importance.sort_values('Importance', ascending=False)
        
        # Visualizar
        plt.figure(figsize=(12, 8))
        sns.barplot(x='Importance', y='Feature', data=feature_importance)
        plt.title('Importancia de Caracter칤sticas')
        plt.xlabel('Importancia')
        plt.ylabel('Caracter칤stica')
        plt.grid(axis='x')
        plt.savefig('titanic_importancia_caracteristicas.png', dpi=300, bbox_inches='tight')
        
    elif best_model_name == 'Regresi칩n Log칤stica':
        # Para regresi칩n log칤stica, podemos obtener los coeficientes
        numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']
        categorical_features = ['Pclass', 'Sex', 'Embarked']
        
        # Obtener nombres de caracter칤sticas despu칠s de one-hot encoding
        ohe = model.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot']
        cat_feature_names = ohe.get_feature_names_out(categorical_features)
        
        # Combinar nombres de caracter칤sticas
        feature_names = np.array(numeric_features + list(cat_feature_names))
        
        # Obtener coeficientes
        coefficients = model.named_steps['model'].coef_[0]
        
        # Crear DataFrame para visualizaci칩n
        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Coefficient': coefficients
        })
        
        # Ordenar por valor absoluto de coeficientes
        feature_importance['AbsCoefficient'] = np.abs(feature_importance['Coefficient'])
        feature_importance = feature_importance.sort_values('AbsCoefficient', ascending=False)
        
        # Visualizar
        plt.figure(figsize=(12, 8))
        colors = ['red' if c < 0 else 'green' for c in feature_importance['Coefficient']]
        sns.barplot(x='Coefficient', y='Feature', data=feature_importance, palette=colors)
        plt.title('Coeficientes de Regresi칩n Log칤stica')
        plt.xlabel('Coeficiente')
        plt.ylabel('Caracter칤stica')
        plt.grid(axis='x')
        plt.savefig('titanic_coeficientes.png', dpi=300, bbox_inches='tight')
    
    # An치lisis de errores
    y_pred_final = model.predict(X_test)
    errors = y_test != y_pred_final
    
    # Crear DataFrame con los datos de prueba y resultados
    X_test_reset = X_test.reset_index(drop=True)
    error_analysis = pd.DataFrame({
        'Real': y_test.reset_index(drop=True),
        'Predicci칩n': y_pred_final,
        'Error': errors.reset_index(drop=True),
        'Probabilidad': model.predict_proba(X_test)[:, 1]
    })
    
    # Combinar con caracter칤sticas originales
    for col in X_test.columns:
        error_analysis[col] = X_test_reset[col]
    
    # Mostrar ejemplos de errores
    print("\nEjemplos de predicciones incorrectas:")
    print(error_analysis[error_analysis['Error']].head())
    
    # Analizar errores por caracter칤sticas
    plt.figure(figsize=(12, 6))
    sns.countplot(x='Sex', hue='Error', data=error_analysis)
    plt.title('Distribuci칩n de Errores por Sexo')
    plt.xlabel('Sexo')
    plt.ylabel('Cantidad')
    plt.legend(title='Error', labels=['Correcto', 'Incorrecto'])
    plt.savefig('titanic_errores_sexo.png', dpi=300, bbox_inches='tight')
    
    plt.figure(figsize=(12, 6))
    sns.countplot(x='Pclass', hue='Error', data=error_analysis)
    plt.title('Distribuci칩n de Errores por Clase')
    plt.xlabel('Clase')
    plt.ylabel('Cantidad')
    plt.legend(title='Error', labels=['Correcto', 'Incorrecto'])
    plt.savefig('titanic_errores_clase.png', dpi=300, bbox_inches='tight')
    
    # An치lisis de errores por edad
    plt.figure(figsize=(12, 6))
    sns.boxplot(x='Error', y='Age', data=error_analysis)
    plt.title('Distribuci칩n de Edades por Error')
    plt.xlabel('Error')
    plt.ylabel('Edad')
    plt.xticks([0, 1], ['Correcto', 'Incorrecto'])
    plt.savefig('titanic_errores_edad.png', dpi=300, bbox_inches='tight')

# Funci칩n para cargar el modelo
def cargar_modelo(filename):
    """
    Carga un modelo guardado desde un archivo joblib.
    
    Args:
        filename (str): La ruta al archivo .joblib del modelo.
        
    Returns:
        object: El modelo cargado, o None si ocurre un error.
    """
    try:
        model = joblib.load(filename)
        print(f"\nModelo '{filename}' cargado exitosamente.")
        return model
    except FileNotFoundError:
        print(f"\nError: No se encontr칩 el archivo del modelo en '{filename}'")
        return None
    except Exception as e:
        print(f"\nOcurri칩 un error al cargar el modelo: {e}")
        return None

# Funci칩n para hacer predicciones con nuevos datos
def hacer_prediccion(model, new_data):
    """
    Hace predicciones con nuevos datos.
    
    Args:
        model: Modelo entrenado
        new_data: Nuevos datos para predecir
        
    Returns:
        array: Predicciones
    """
    predictions = model.predict(new_data)
    probabilities = model.predict_proba(new_data)[:, 1]
    
    results = pd.DataFrame({
        'Predicci칩n': predictions,
        'Probabilidad de Supervivencia': probabilities
    })
    
    return results

# Funci칩n principal
def main():
    """
    Funci칩n principal que ejecuta todo el flujo de trabajo.
    """
    print("Iniciando an치lisis de supervivencia en el Titanic...")
    
    # Cargar datos
    data = cargar_datos()
    
    # Explorar datos
    data = explorar_datos(data)
    
    # Preparar datos
    X_train, X_test, y_train, y_test, preprocessor = preparar_datos(data)
    
    # Entrenar y evaluar modelos
    best_pipeline, best_model_name, results = entrenar_evaluar_modelos(X_train, X_test, y_train, y_test, preprocessor)
    
    # Optimizar hiperpar치metros
    best_model = optimizar_hiperparametros(best_pipeline, best_model_name, X_train, y_train, X_test, y_test)

    # Guardar el modelo optimizado
    if best_model:
        guardar_modelo(best_model, 'titanic_survival_model.joblib')

    # Interpretar modelo
    interpretar_modelo(best_model, best_model_name, X_test, y_test, preprocessor)
    
    # Ejemplo de predicci칩n con nuevos datos
    print("\nEjemplo de predicci칩n con nuevos pasajeros:")
    
    # Cargamos el modelo desde el disco
    modelo_produccion = cargar_modelo('titanic_survival_model.joblib')
    
    if modelo_produccion:
        # Crear algunos pasajeros de ejemplo
        new_passengers = pd.DataFrame({
            'Pclass': [1, 3, 2],
            'Sex': ['female', 'male', 'female'],
            'Age': [29, 35, 10],
            'SibSp': [0, 1, 1],
            'Parch': [0, 0, 1],
            'Fare': [100, 15, 30],
            'Embarked': ['S', 'S', 'C']
        })
        
        print("\nNuevos pasajeros:")
        print(new_passengers)
        
        # Hacer predicciones con el modelo cargado
        predictions = hacer_prediccion(modelo_produccion, new_passengers)
        
        # Mostrar resultados
        result_df = pd.concat([new_passengers, predictions], axis=1)
        print("\nResultados de predicci칩n:")
        print(result_df)

    print("\nAn치lisis completado.")
    
    # Mostrar resultados
    result_df = pd.concat([new_passengers, predictions], axis=1)
    print("\nResultados de predicci칩n:")
    print(result_df)
    
    print("\nAn치lisis completado. Todas las visualizaciones han sido guardadas como archivos PNG.")

# Ejecutar el programa si se llama directamente
if __name__ == "__main__":
    main()

